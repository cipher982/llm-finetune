{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import openai\n",
    "\n",
    "\n",
    "sys.path.append(\"../extra\")\n",
    "from prompt import PROMPT\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 757 augmented examples\n"
     ]
    }
   ],
   "source": [
    "df = []\n",
    "with open(\"../data/rb_augmented.jsonl\", \"r\") as f:\n",
    "    for line in f:\n",
    "        df.append(json.loads(line))\n",
    "\n",
    "# convert to df\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "print(f\"Loaded {len(df):,} augmented examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_examples(dataset: pd.DataFrame, n: int = 3) -> str:\n",
    "    examples = \"\"\n",
    "    \n",
    "    sample_dataset = dataset.sample(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        q = sample_dataset.iloc[i][\"question\"]\n",
    "        a = sample_dataset.iloc[i][\"output\"]\n",
    "        examples += f\"Q: {q}\\nA: {a}\\n\\n\"\n",
    "\n",
    "    return examples\n",
    "\n",
    "\n",
    "def build_augmentation_prompt(prompt: str, examples: str, n_outputs: int) -> str:\n",
    "    \"\"\"Take in the original prompt and examples to build a new prompt for augmentation.\"\"\"\n",
    "\n",
    "    prompt_and_examples = prompt + \"\\n\\n\" + examples\n",
    "    tail_str = f\"Now use some random dimensions and metrics and the examples as a style guide and provide {n_outputs} more examples of questions and outputs\"\n",
    "    prompt_and_examples = prompt_and_examples + \"\\n\\n\" + tail_str\n",
    "    return prompt_and_examples\n",
    "\n",
    "\n",
    "def query_openai(prompt: str) -> str:\n",
    "    \"\"\"Query OpenAI API with the given prompt and return the result.\"\"\"\n",
    "    output = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-0613\",\n",
    "        messages =[{\"role\": \"user\", \"content\": prompt}],\n",
    "        max_tokens=5000,\n",
    "        temperature=0.6,\n",
    "    )\n",
    "    return output.choices[0].message.content\n",
    "\n",
    "\n",
    "def extract_qa(text: str) -> pd.DataFrame:\n",
    "    # Regular expressions for questions and answers\n",
    "    question_pattern = r\"Q: (.*?)\\n\"\n",
    "    answer_pattern = r\"A: ```json\\n(.*?)```\"\n",
    "\n",
    "    # Find all questions and answers\n",
    "    questions = re.findall(question_pattern, text, re.DOTALL)\n",
    "    answers = re.findall(answer_pattern, text, re.DOTALL)\n",
    "\n",
    "    # Rewrap the answers to add the markdown code block\n",
    "    answers = [f\"```json\\n{a}```\" for a in answers]\n",
    "\n",
    "    # Determine the length of questions and answers\n",
    "    q_len = len(questions)\n",
    "    a_len = len(answers)\n",
    "\n",
    "    # If questions and answers don\"t align, fill the shorter one with None values to avoid failure\n",
    "    if q_len < a_len:\n",
    "        questions += [None] * (a_len - q_len)\n",
    "    elif a_len < q_len:\n",
    "        answers += [None] * (q_len - a_len)\n",
    "\n",
    "    # Create a DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        \"question\": questions,\n",
    "        \"answer\": answers\n",
    "    })\n",
    "\n",
    "    # Remove rows where both question and answer are None\n",
    "    df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dataframes = []\n",
    "for _ in tqdm(range(500)):\n",
    "    try:\n",
    "        # Sample n examples from the dataframe\n",
    "        examples = build_examples(df, 3)\n",
    "\n",
    "        # Build the prompt for the LLM\n",
    "        prompt = build_augmentation_prompt(PROMPT, examples, 10)\n",
    "\n",
    "        # Query the LLM and return the augmented examples in a string\n",
    "        output = query_openai(prompt)\n",
    "\n",
    "        # Convert the output string to a dataframe\n",
    "        df_augmented = extract_qa(output)\n",
    "\n",
    "        # Append the augmented dataframe to the list\n",
    "        augmented_dataframes.append(df_augmented)\n",
    "\n",
    "        print(f\"Augmented {len(df_augmented)} examples.\")\n",
    "        sleep(5)\n",
    "    except Exception as e:\n",
    "        # Handle the exception (you can print an error message or log it if needed)\n",
    "        print(f\"An error occurred during the iteration: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the list of df to a single df\n",
    "final_df = pd.concat(augmented_dataframes, ignore_index=True)\n",
    "\n",
    "# Save the final df to a pickle file with timestamp in the name\n",
    "fp = f\"../data/augmented_{len(final_df)}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
    "final_df.to_pickle(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Convert to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drop 875 null rows\n",
      "Drop 1110 duplicate rows\n",
      "Drop 547 too short questions rows\n",
      "Writing JSONL with 2306 rows\n"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_pickle(\"../data/aug_4838_20230803/augmented.pkl\")\n",
    "\n",
    "# Drop null\n",
    "len_before = len(df2)\n",
    "df2 = df2.dropna()\n",
    "print(f\"Drop {len_before - len(df2)} null rows\")\n",
    "\n",
    "# Drop duplicates\n",
    "len_before = len(df2)\n",
    "df2 = df2.drop_duplicates()\n",
    "print(f\"Drop {len_before - len(df2)} duplicate rows\")\n",
    "\n",
    "# Drop rows with short questions (likely invalid)\n",
    "len_before = len(df2)\n",
    "df2 = df2[df2['question'].str.len() > 20]\n",
    "print(f\"Drop {len_before - len(df2)} too short questions rows\")\n",
    "\n",
    "# Convert to JSONL\n",
    "print(f\"Writing JSONL with {len(df2)} rows\")\n",
    "json_str = df2.to_json(orient='records', lines=True)\n",
    "with open(\"../data/aug_4838_20230803/augmented.jsonl\", \"w\") as f:\n",
    "    f.write(json_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omnisearch39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
